{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RNN原理\" data-toc-modified-id=\"RNN原理-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>RNN</code>原理</a></span><ul class=\"toc-item\"><li><span><a href=\"#SimpleRNN\" data-toc-modified-id=\"SimpleRNN-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>SimpleRNN</code></a></span></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>LSTM</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#LSTM原理\" data-toc-modified-id=\"LSTM原理-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span><code>LSTM</code>原理</a></span></li><li><span><a href=\"#LSTM结构\" data-toc-modified-id=\"LSTM结构-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><code>LSTM</code>结构</a></span></li><li><span><a href=\"#peephole机制\" data-toc-modified-id=\"peephole机制-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span><code>peephole</code>机制</a></span></li></ul></li><li><span><a href=\"#GRU\" data-toc-modified-id=\"GRU-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>GRU</code></a></span></li></ul></li><li><span><a href=\"#RNN实现\" data-toc-modified-id=\"RNN实现-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><code>RNN</code>实现</a></span><ul class=\"toc-item\"><li><span><a href=\"#SimpleRNN层\" data-toc-modified-id=\"SimpleRNN层-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><code>SimpleRNN</code>层</a></span></li><li><span><a href=\"#LSTM层\" data-toc-modified-id=\"LSTM层-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><code>LSTM</code>层</a></span></li><li><span><a href=\"#GRU层\" data-toc-modified-id=\"GRU层-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><code>GRU</code>层</a></span></li><li><span><a href=\"#RNN训练流程\" data-toc-modified-id=\"RNN训练流程-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>RNN</code>训练流程</a></span><ul class=\"toc-item\"><li><span><a href=\"#训练数据\" data-toc-modified-id=\"训练数据-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>训练数据</a></span></li><li><span><a href=\"#定义模型\" data-toc-modified-id=\"定义模型-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>定义模型</a></span></li><li><span><a href=\"#训练模型\" data-toc-modified-id=\"训练模型-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>训练模型</a></span></li></ul></li></ul></li><li><span><a href=\"#RNN示例：字符级文本生成\" data-toc-modified-id=\"RNN示例：字符级文本生成-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><code>RNN</code>示例：字符级文本生成</a></span><ul class=\"toc-item\"><li><span><a href=\"#数据集\" data-toc-modified-id=\"数据集-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>数据集</a></span></li><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>数据预处理</a></span></li><li><span><a href=\"#创建模型\" data-toc-modified-id=\"创建模型-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>创建模型</a></span></li><li><span><a href=\"#训练模型\" data-toc-modified-id=\"训练模型-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>训练模型</a></span></li><li><span><a href=\"#获取最优模型\" data-toc-modified-id=\"获取最优模型-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>获取最优模型</a></span></li><li><span><a href=\"#保存模型\" data-toc-modified-id=\"保存模型-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>保存模型</a></span></li><li><span><a href=\"#文本生成\" data-toc-modified-id=\"文本生成-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>文本生成</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `RNN`原理\n",
    "- `Recurrent Neural Network`，循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T10:57:49.560775Z",
     "start_time": "2020-04-16T10:57:49.555762Z"
    }
   },
   "source": [
    "## `SimpleRNN`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `SimpleRNN`其结构如下图所示：\n",
    "![](../images/RNN.png)\n",
    "    - 输入为一个向量序列$\\{x_0,x_1,x_2...x_n\\}$ ；\n",
    "    - 在时间步 $t$，序列的元素 $x_t$ 和上一时间步的输出 $h_{t-1} $一起，经过`RNN`单元处理，产生输出 $h_t$;\n",
    "   $$h_t=ϕ(Wx_t+Uh_{t−1})$$\n",
    "   $$y_t=Vh_t$$\n",
    "    - $h_t$ 为隐藏层状态，携带了序列截止时间步 $t$ 的信息；$y_t$ 为时间步 $t$ 的输出；$h_t$ 继续作为下一时间步的输入\n",
    "    - 整个序列被处理完，最终的输出 $y_n$ 即为`RNN`的输出；根据情况，也可返回所有的输出序列 $\\{y_0,y_1,y_2...y_n\\}$\n",
    "    - 序列的每个元素是经过***同一个***`RNN`处理，因此待学习的参数只有一组：$W,U,V$\n",
    "        \n",
    "           \n",
    "- 序列元素依次经过`RNN`的激活`(sigmoid/tanh)`函数的处理，存在信息丢失；并且在训练时反向传播会导致梯度消失，因此只能储存**短期记忆**\n",
    "    - 例如训练单词`it`对应的向量时，只能利用`time`和`is`对应的信息，而`what`对应的信息丢失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T15:37:04.172834Z",
     "start_time": "2020-04-16T15:37:04.163707Z"
    }
   },
   "source": [
    "### `LSTM`原理\n",
    "- `Long Short-Term Memory`，其框架如下所示，`LSTM`单元利用当前输入、短期记忆和长期记忆，更新长期和短期记忆，并产生输出\n",
    "![](../images/lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LSTM`结构\n",
    "- `LSTM`的结构如下图所示，包含四个门：`forget gate`,`learn gate`,`remember gate`,`ouput(use) gate`\n",
    "![](../images/lstm结构.png)\n",
    "    - `forget gate`：决定**长期记忆**$c_t$中哪些信息该保留，哪些该忘记\n",
    "        - 首先整合当前输入$x_t$和短期记忆$h_{t-1}$，输出一个向量$f_t$；\n",
    "        - $f_t$的值介于$0-1$之间，每一位对应于**长期记忆**的一个数字，$1$表示完全保留，$0$表示完全丢弃\n",
    "            $$f_t=\\sigma(W_f[h_{t-1},x_t]+b_f)$$\n",
    "            $$Out_f = c_{t-1}\\cdot f_t$$\n",
    "        \n",
    "    - `learn gate`：决定短期记忆和当前输入中学到的信息\n",
    "        - 首先整合 $x_t$ 和短期记忆 $h_{t-1}$ 的信息 $\\hat c_t$\n",
    "        - 然后通过  $x_t$ 和 $h_{t-1}$ 获得一个遗忘因子 $i_t$，其值位于$0-1$之间\n",
    "        - 再将上两步的结果结合\n",
    "            $$\\hat c_t=tanh(W_n[h_{t-1},x_t]+b_n)$$  \n",
    "            $$i_t=\\sigma(W_i[h_{t-1},x_t]+b_i)$$\n",
    "            $$Out_n = i_t\\cdot \\hat c_t$$\n",
    "\n",
    "    - `remember gate`：整合上一步的长短期记忆，更新长期记忆\n",
    "$$c_t = Out_f+Out_n$$\n",
    "            \n",
    "    - `output(use) gate`：整合上一步的长短期记忆，更新短期记忆\n",
    "$$o_t=\\sigma(W_o[h_{t-1},x_t]+b_o)$$\n",
    "$$h_t=o_t\\cdot tanh(c_t)$$\n",
    "    \n",
    "- 短期记忆$h_t$，即为`LSTM`当前时间步$t$的输出\n",
    "\n",
    "  \n",
    "- 综上`LSTM`单元的训练参数有四组：`forget gate`参数$\\{W_f,b_f\\}$，`learn gate`参数$\\{W_n,b_n\\}$和$\\{W_i,b_i\\}$，`output gate`参数$\\{W_o,b_o\\}$\n",
    "     \n",
    "     \n",
    "- `LSTM`中不同位置处`sigmoid`和`tanh`激活函数的选择，向量相加加或相乘的确定，具有一定的随意性。之所以选择现结构，是因为在实践中有效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `peephole`机制\n",
    "- 门机制中的`sigmoid`激活函数，将输入转化成$0-1$数值；`sigmoid`乘以另一向量，即可决定保留该向量的哪些信息；\n",
    "- 上述`LSTM`结构中三个`sigmoid`函数的输入都是当前输入和短期记忆$[h_{t_1},x_t]$，即决定`LSTM`单元保留哪些信息的都是短期记忆；\n",
    "- `peephole connections`：将长期记忆也加入到`sigmoid`激活函数的输入中，其在`LSTM`中的决策参与度提高了，即长期和短期记忆共同决定保留哪些信息、丢弃哪些信息\n",
    "![](../images/peephole.png)\n",
    "$$f_t=\\sigma(W_f[c_{t-1},h_{t-1},x_t]+b_f)$$\n",
    "$$i_t=\\sigma(W_i[c_{t-1},h_{t-1},x_t]+b_i)$$\n",
    "$$o_t=\\sigma(W_o[c_{t-1},h_{t-1},x_t]+b_o)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T08:26:55.692353Z",
     "start_time": "2020-04-17T08:26:55.688024Z"
    }
   },
   "source": [
    "## `GRU`\n",
    "- `Gated Recurrent Unit`，将`forget gate`和`learn gate`整合成单个的`update gate`，单元状态(长期记忆)$c_{t}$与隐藏状态(短期记忆)$h_t$合并\n",
    "![](../images/gru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `RNN`实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T07:04:28.602899Z",
     "start_time": "2020-04-23T07:04:28.311358Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T10:54:53.694183Z",
     "start_time": "2020-04-22T10:54:53.688821Z"
    }
   },
   "source": [
    "## `SimpleRNN`层\n",
    "对输入序列的每个向量$x_t$，进行如下计算：\n",
    "$h_t=tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{(t−1)}+b_{hh})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T07:17:31.480404Z",
     "start_time": "2020-04-23T07:17:31.473169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状： torch.Size([5, 3, 6])\n",
      "输出形状： torch.Size([5, 3, 10])  隐藏层状态形状： torch.Size([2, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "# 指定输入的特征量，隐藏状态的长度，rnn的层数\n",
    "rnn = nn.RNN(\n",
    "    input_size=6,\n",
    "    hidden_size=10,\n",
    "    num_layers=2,\n",
    "    batch_first=True,  # 输入和输出张量形状：batch,seq,feature\n",
    "    bidirectional=False,  # 双向RNN\n",
    ")\n",
    "\n",
    "# 输入张量：\n",
    "input = torch.randn(5, 3, 6)  # batch,seq,feature\n",
    "h0 = torch.randn(2, 5, 10)  # num_layers,batch,hidden_size\n",
    "print(\"输入形状：\", input.shape)\n",
    "\n",
    "output, hn = rnn(input, h0)\n",
    "print(\"输出形状：\", output.shape, \" 隐藏层状态形状：\", hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T07:17:37.735587Z",
     "start_time": "2020-04-23T07:17:37.730022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入向量对应的权重 W_ih： torch.Size([10, 6])\n",
      "隐藏状态对应的权重 W_hh： torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"输入向量对应的权重 W_ih：\",rnn.weight_ih_l0.shape)\n",
    "print(\"隐藏状态对应的权重 W_hh：\",rnn.weight_hh_l0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:06:12.539402Z",
     "start_time": "2020-04-22T12:06:12.533463Z"
    }
   },
   "source": [
    "## `LSTM`层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T07:36:27.978002Z",
     "start_time": "2020-04-23T07:36:27.970245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状： torch.Size([5, 3, 10])\n",
      "hidden state： torch.Size([2, 5, 10])\n",
      "cell state： torch.Size([2, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(\n",
    "    input_size=6,\n",
    "    hidden_size=10,\n",
    "    num_layers=2,\n",
    "    batch_first=True,  # 输入和输出张量形状：batch,seq,feature\n",
    "    bidirectional=False,\n",
    ")\n",
    "input = torch.randn(5, 3, 6)\n",
    "h0 = torch.randn(2, 5, 10) # num_layer,batch,hidden\n",
    "c0 = torch.randn(2, 5, 10)\n",
    "\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "print(\"输出形状：\", output.shape)\n",
    "print(\"hidden state：\", hn.shape)\n",
    "print(\"cell state：\", cn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRU`层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:08:42.939263Z",
     "start_time": "2020-04-22T12:08:42.931554Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:02:42.716623Z",
     "start_time": "2020-04-22T12:02:42.707845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 15])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RNN`训练流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:04:03.699786Z",
     "start_time": "2020-04-17T12:04:03.614319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# 序列数据\n",
    "seq_length = 20\n",
    "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
    "data = np.sin(time_steps)\n",
    "data.resize((seq_length + 1, 1))\n",
    "\n",
    "x = data[:-1]  # 数据\n",
    "y = data[1:]  # 标签\n",
    "\n",
    "# 图示数据\n",
    "plt.plot(time_steps[1:], x, 'r.', label='input,  x')\n",
    "plt.plot(time_steps[1:], y, 'b.', label='target, y')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:04:09.147419Z",
     "start_time": "2020-04-17T12:04:09.141076Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = r_out.view(-1, self.hidden_dim)\n",
    "        output = self.fc(r_out)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:08:52.736633Z",
     "start_time": "2020-04-17T12:08:52.688121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([1, 21, 1])\n",
      "Output size: torch.Size([21, 1])\n",
      "Hidden state size: torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 检测正确建模\n",
    "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
    "\n",
    "test_input = torch.Tensor(data).unsqueeze(0)\n",
    "print('Input size:', test_input.size())\n",
    "\n",
    "test_out, test_h = test_rnn(test_input, None)\n",
    "print('Output size:', test_out.size())\n",
    "print('Hidden state size:', test_h.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:13:25.002653Z",
     "start_time": "2020-04-17T12:13:24.997361Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参数\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_dim = 32\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:14:23.447781Z",
     "start_time": "2020-04-17T12:14:23.442151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:16:40.255210Z",
     "start_time": "2020-04-17T12:16:40.249909Z"
    }
   },
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:26:43.074801Z",
     "start_time": "2020-04-17T12:26:43.067730Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train(rnn, n_steps, print_every):\n",
    "    hidden = None\n",
    "    for batch_i, step in enumerate(range(n_steps)):\n",
    "        x_tensor = torch.Tensor(x).unsqueeze(0)\n",
    "        y_tensor = torch.Tensor(y)\n",
    "\n",
    "        # 前向推理\n",
    "        prediction, hidden = rnn(x_tensor, hidden)\n",
    "        hidden = hidden.data\n",
    "\n",
    "        # 损失函数\n",
    "        loss = criterion(prediction, y_tensor)\n",
    "\n",
    "        # 梯度归零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新梯度\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_i % print_every == 0:\n",
    "            print('Loss: ', loss.item())\n",
    "            plt.plot(time_steps[1:], x, 'r.')\n",
    "            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.')\n",
    "            plt.show()\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:26:49.348691Z",
     "start_time": "2020-04-17T12:26:48.906766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.40589970350265503\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.035483404994010925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.012853428721427917\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00824706070125103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.010340889915823936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_steps = 75\n",
    "print_every = 15\n",
    "\n",
    "# 训练\n",
    "trained_rnn = train(rnn, n_steps, print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `RNN`示例：字符级文本生成\n",
    "\n",
    "![](images/charseq.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:34:31.959282Z",
     "start_time": "2020-04-17T12:34:31.954276Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:35:46.815654Z",
     "start_time": "2020-04-17T12:35:46.808118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('datasets/anna.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text[:100]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:38:12.157786Z",
     "start_time": "2020-04-17T12:38:12.012561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 41, 28, 66,  7, 21, 47, 58,  4, 35, 35, 35, 23, 28, 66, 66, 31,\n",
       "       58,  9, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本向量化\n",
    "\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "encoded[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:45:43.290190Z",
     "start_time": "2020-04-17T12:45:43.284573Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:45:44.312299Z",
     "start_time": "2020-04-17T12:45:44.306700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = np.array([[3, 5, 1]])\n",
    "one_hot = one_hot_encode(test_seq, 8)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:04:38.354611Z",
     "start_time": "2020-04-17T13:04:38.346329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[77 41 28 66  7 21 47 58  4 35]\n",
      " [39 81 37 58  7 41 28  7 58 28]\n",
      " [21 37 67 58 81 47 58 28 58  9]\n",
      " [39 58  7 41 21 58 11 41 12 21]]\n",
      "\n",
      "y\n",
      " [[41 28 66  7 21 47 58  4 35 35]\n",
      " [81 37 58  7 41 28  7 58 28  7]\n",
      " [37 67 58 81 47 58 28 58  9 81]\n",
      " [58  7 41 21 58 11 41 12 21  9]]\n"
     ]
    }
   ],
   "source": [
    "# 创建批量数据\n",
    "def get_batches(arr, batch_size, seq_length):\n",
    "\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n + seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n + seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y\n",
    "\n",
    "\n",
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)\n",
    "print('x\\n', x[:4, :10])\n",
    "print('\\ny\\n', y[:4, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:07:14.972822Z",
     "start_time": "2020-04-17T13:07:14.967024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# gpu 可用\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if (train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else:\n",
    "    print(\n",
    "        'No GPU available, training on CPU; consider making n_epochs very small.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:32:57.432232Z",
     "start_time": "2020-04-17T13:32:57.422982Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 tokens,\n",
    "                 n_hidden=256,\n",
    "                 n_layers=2,\n",
    "                 drop_prob=0.5,\n",
    "                 lr=0.001):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "\n",
    "        self.lstm = nn.LSTM(len(self.chars),\n",
    "                            n_hidden,\n",
    "                            n_layers,\n",
    "                            dropout=drop_prob,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size,\n",
    "                                 self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size,\n",
    "                                 self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size,\n",
    "                                 self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size,\n",
    "                                 self.n_hidden).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:33:03.695018Z",
     "start_time": "2020-04-17T13:33:03.683918Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net,\n",
    "          data,\n",
    "          epochs=10,\n",
    "          batch_size=10,\n",
    "          seq_length=10,\n",
    "          lr=0.001,\n",
    "          clip=5,\n",
    "          val_frac=0.1,\n",
    "          print_every=10):\n",
    "    net.train()\n",
    "\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_idx = int(len(data) * (1 - val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "\n",
    "    if train_on_gpu:\n",
    "        net.cuda()\n",
    "\n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(batch_size)\n",
    "\n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "            if train_on_gpu:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            output, h = net(inputs, h)\n",
    "\n",
    "            loss = criterion(output,\n",
    "                             targets.view(batch_size * seq_length).long())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            if counter % print_every == 0:\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    inputs, targets = x, y\n",
    "                    if (train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(\n",
    "                        output,\n",
    "                        targets.view(batch_size * seq_length).long())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                net.train()\n",
    "\n",
    "                print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:33:05.189087Z",
     "start_time": "2020-04-17T13:33:05.174433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:36:52.267597Z",
     "start_time": "2020-04-17T13:34:33.695859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Step: 10... Loss: 3.2684... Val Loss: 3.2099\n",
      "Epoch: 1/20... Step: 20... Loss: 3.1553... Val Loss: 3.1399\n",
      "Epoch: 1/20... Step: 30... Loss: 3.1438... Val Loss: 3.1250\n",
      "Epoch: 1/20... Step: 40... Loss: 3.1109... Val Loss: 3.1204\n",
      "Epoch: 1/20... Step: 50... Loss: 3.1416... Val Loss: 3.1175\n",
      "Epoch: 1/20... Step: 60... Loss: 3.1164... Val Loss: 3.1145\n",
      "Epoch: 1/20... Step: 70... Loss: 3.1047... Val Loss: 3.1109\n",
      "Epoch: 1/20... Step: 80... Loss: 3.1169... Val Loss: 3.1029\n",
      "Epoch: 1/20... Step: 90... Loss: 3.1012... Val Loss: 3.0809\n",
      "Epoch: 1/20... Step: 100... Loss: 3.0419... Val Loss: 3.0239\n",
      "Epoch: 1/20... Step: 110... Loss: 2.9835... Val Loss: 2.9680\n",
      "Epoch: 1/20... Step: 120... Loss: 2.8329... Val Loss: 2.8223\n",
      "Epoch: 1/20... Step: 130... Loss: 2.8383... Val Loss: 2.8556\n",
      "Epoch: 2/20... Step: 140... Loss: 2.7164... Val Loss: 2.6663\n",
      "Epoch: 2/20... Step: 150... Loss: 2.6229... Val Loss: 2.5753\n",
      "Epoch: 2/20... Step: 160... Loss: 2.5504... Val Loss: 2.5114\n",
      "Epoch: 2/20... Step: 170... Loss: 2.4817... Val Loss: 2.4664\n",
      "Epoch: 2/20... Step: 180... Loss: 2.4539... Val Loss: 2.4292\n",
      "Epoch: 2/20... Step: 190... Loss: 2.4003... Val Loss: 2.3941\n",
      "Epoch: 2/20... Step: 200... Loss: 2.4008... Val Loss: 2.3660\n",
      "Epoch: 2/20... Step: 210... Loss: 2.3633... Val Loss: 2.3358\n",
      "Epoch: 2/20... Step: 220... Loss: 2.3302... Val Loss: 2.3069\n",
      "Epoch: 2/20... Step: 230... Loss: 2.3156... Val Loss: 2.2811\n",
      "Epoch: 2/20... Step: 240... Loss: 2.2904... Val Loss: 2.2567\n",
      "Epoch: 2/20... Step: 250... Loss: 2.2315... Val Loss: 2.2277\n",
      "Epoch: 2/20... Step: 260... Loss: 2.1987... Val Loss: 2.1988\n",
      "Epoch: 2/20... Step: 270... Loss: 2.2062... Val Loss: 2.1753\n",
      "Epoch: 3/20... Step: 280... Loss: 2.2010... Val Loss: 2.1486\n",
      "Epoch: 3/20... Step: 290... Loss: 2.1719... Val Loss: 2.1246\n",
      "Epoch: 3/20... Step: 300... Loss: 2.1350... Val Loss: 2.1097\n",
      "Epoch: 3/20... Step: 310... Loss: 2.1090... Val Loss: 2.0875\n",
      "Epoch: 3/20... Step: 320... Loss: 2.0769... Val Loss: 2.0644\n",
      "Epoch: 3/20... Step: 330... Loss: 2.0504... Val Loss: 2.0463\n",
      "Epoch: 3/20... Step: 340... Loss: 2.0679... Val Loss: 2.0248\n",
      "Epoch: 3/20... Step: 350... Loss: 2.0545... Val Loss: 2.0122\n",
      "Epoch: 3/20... Step: 360... Loss: 1.9831... Val Loss: 1.9931\n",
      "Epoch: 3/20... Step: 370... Loss: 2.0144... Val Loss: 1.9765\n",
      "Epoch: 3/20... Step: 380... Loss: 1.9839... Val Loss: 1.9569\n",
      "Epoch: 3/20... Step: 390... Loss: 1.9620... Val Loss: 1.9429\n",
      "Epoch: 3/20... Step: 400... Loss: 1.9336... Val Loss: 1.9274\n",
      "Epoch: 3/20... Step: 410... Loss: 1.9439... Val Loss: 1.9143\n",
      "Epoch: 4/20... Step: 420... Loss: 1.9417... Val Loss: 1.8957\n",
      "Epoch: 4/20... Step: 430... Loss: 1.9184... Val Loss: 1.8853\n",
      "Epoch: 4/20... Step: 440... Loss: 1.9016... Val Loss: 1.8775\n",
      "Epoch: 4/20... Step: 450... Loss: 1.8396... Val Loss: 1.8572\n",
      "Epoch: 4/20... Step: 460... Loss: 1.8320... Val Loss: 1.8479\n",
      "Epoch: 4/20... Step: 470... Loss: 1.8746... Val Loss: 1.8396\n",
      "Epoch: 4/20... Step: 480... Loss: 1.8527... Val Loss: 1.8245\n",
      "Epoch: 4/20... Step: 490... Loss: 1.8512... Val Loss: 1.8171\n",
      "Epoch: 4/20... Step: 500... Loss: 1.8388... Val Loss: 1.8028\n",
      "Epoch: 4/20... Step: 510... Loss: 1.8212... Val Loss: 1.7942\n",
      "Epoch: 4/20... Step: 520... Loss: 1.8299... Val Loss: 1.7832\n",
      "Epoch: 4/20... Step: 530... Loss: 1.7957... Val Loss: 1.7752\n",
      "Epoch: 4/20... Step: 540... Loss: 1.7593... Val Loss: 1.7640\n",
      "Epoch: 4/20... Step: 550... Loss: 1.8066... Val Loss: 1.7529\n",
      "Epoch: 5/20... Step: 560... Loss: 1.7772... Val Loss: 1.7441\n",
      "Epoch: 5/20... Step: 570... Loss: 1.7592... Val Loss: 1.7396\n",
      "Epoch: 5/20... Step: 580... Loss: 1.7381... Val Loss: 1.7289\n",
      "Epoch: 5/20... Step: 590... Loss: 1.7341... Val Loss: 1.7203\n",
      "Epoch: 5/20... Step: 600... Loss: 1.7233... Val Loss: 1.7146\n",
      "Epoch: 5/20... Step: 610... Loss: 1.7124... Val Loss: 1.7046\n",
      "Epoch: 5/20... Step: 620... Loss: 1.7138... Val Loss: 1.7029\n",
      "Epoch: 5/20... Step: 630... Loss: 1.7224... Val Loss: 1.6903\n",
      "Epoch: 5/20... Step: 640... Loss: 1.6983... Val Loss: 1.6863\n",
      "Epoch: 5/20... Step: 650... Loss: 1.6905... Val Loss: 1.6752\n",
      "Epoch: 5/20... Step: 660... Loss: 1.6594... Val Loss: 1.6704\n",
      "Epoch: 5/20... Step: 670... Loss: 1.6819... Val Loss: 1.6640\n",
      "Epoch: 5/20... Step: 680... Loss: 1.6872... Val Loss: 1.6568\n",
      "Epoch: 5/20... Step: 690... Loss: 1.6595... Val Loss: 1.6552\n",
      "Epoch: 6/20... Step: 700... Loss: 1.6551... Val Loss: 1.6462\n",
      "Epoch: 6/20... Step: 710... Loss: 1.6496... Val Loss: 1.6408\n",
      "Epoch: 6/20... Step: 720... Loss: 1.6318... Val Loss: 1.6312\n",
      "Epoch: 6/20... Step: 730... Loss: 1.6589... Val Loss: 1.6292\n",
      "Epoch: 6/20... Step: 740... Loss: 1.6186... Val Loss: 1.6267\n",
      "Epoch: 6/20... Step: 750... Loss: 1.6037... Val Loss: 1.6149\n",
      "Epoch: 6/20... Step: 760... Loss: 1.6439... Val Loss: 1.6133\n",
      "Epoch: 6/20... Step: 770... Loss: 1.6214... Val Loss: 1.6056\n",
      "Epoch: 6/20... Step: 780... Loss: 1.6137... Val Loss: 1.6016\n",
      "Epoch: 6/20... Step: 790... Loss: 1.5932... Val Loss: 1.5931\n",
      "Epoch: 6/20... Step: 800... Loss: 1.6040... Val Loss: 1.5969\n",
      "Epoch: 6/20... Step: 810... Loss: 1.5964... Val Loss: 1.5870\n",
      "Epoch: 6/20... Step: 820... Loss: 1.5575... Val Loss: 1.5828\n",
      "Epoch: 6/20... Step: 830... Loss: 1.6043... Val Loss: 1.5756\n",
      "Epoch: 7/20... Step: 840... Loss: 1.5554... Val Loss: 1.5712\n",
      "Epoch: 7/20... Step: 850... Loss: 1.5727... Val Loss: 1.5696\n",
      "Epoch: 7/20... Step: 860... Loss: 1.5676... Val Loss: 1.5616\n",
      "Epoch: 7/20... Step: 870... Loss: 1.5734... Val Loss: 1.5599\n",
      "Epoch: 7/20... Step: 880... Loss: 1.5708... Val Loss: 1.5537\n",
      "Epoch: 7/20... Step: 890... Loss: 1.5672... Val Loss: 1.5536\n",
      "Epoch: 7/20... Step: 900... Loss: 1.5418... Val Loss: 1.5477\n",
      "Epoch: 7/20... Step: 910... Loss: 1.5274... Val Loss: 1.5427\n",
      "Epoch: 7/20... Step: 920... Loss: 1.5348... Val Loss: 1.5420\n",
      "Epoch: 7/20... Step: 930... Loss: 1.5371... Val Loss: 1.5350\n",
      "Epoch: 7/20... Step: 940... Loss: 1.5318... Val Loss: 1.5341\n",
      "Epoch: 7/20... Step: 950... Loss: 1.5469... Val Loss: 1.5285\n",
      "Epoch: 7/20... Step: 960... Loss: 1.5396... Val Loss: 1.5269\n",
      "Epoch: 7/20... Step: 970... Loss: 1.5491... Val Loss: 1.5230\n",
      "Epoch: 8/20... Step: 980... Loss: 1.5196... Val Loss: 1.5151\n",
      "Epoch: 8/20... Step: 990... Loss: 1.5156... Val Loss: 1.5145\n",
      "Epoch: 8/20... Step: 1000... Loss: 1.5137... Val Loss: 1.5077\n",
      "Epoch: 8/20... Step: 1010... Loss: 1.5480... Val Loss: 1.5094\n",
      "Epoch: 8/20... Step: 1020... Loss: 1.5163... Val Loss: 1.5056\n",
      "Epoch: 8/20... Step: 1030... Loss: 1.4934... Val Loss: 1.5022\n",
      "Epoch: 8/20... Step: 1040... Loss: 1.5129... Val Loss: 1.5031\n",
      "Epoch: 8/20... Step: 1050... Loss: 1.4812... Val Loss: 1.4964\n",
      "Epoch: 8/20... Step: 1060... Loss: 1.4982... Val Loss: 1.4925\n",
      "Epoch: 8/20... Step: 1070... Loss: 1.4994... Val Loss: 1.4875\n",
      "Epoch: 8/20... Step: 1080... Loss: 1.4974... Val Loss: 1.4881\n",
      "Epoch: 8/20... Step: 1090... Loss: 1.4706... Val Loss: 1.4843\n",
      "Epoch: 8/20... Step: 1100... Loss: 1.4743... Val Loss: 1.4796\n",
      "Epoch: 8/20... Step: 1110... Loss: 1.4622... Val Loss: 1.4781\n",
      "Epoch: 9/20... Step: 1120... Loss: 1.4796... Val Loss: 1.4796\n",
      "Epoch: 9/20... Step: 1130... Loss: 1.4893... Val Loss: 1.4764\n",
      "Epoch: 9/20... Step: 1140... Loss: 1.4759... Val Loss: 1.4679\n",
      "Epoch: 9/20... Step: 1150... Loss: 1.4925... Val Loss: 1.4718\n",
      "Epoch: 9/20... Step: 1160... Loss: 1.4514... Val Loss: 1.4657\n",
      "Epoch: 9/20... Step: 1170... Loss: 1.4605... Val Loss: 1.4629\n",
      "Epoch: 9/20... Step: 1180... Loss: 1.4495... Val Loss: 1.4687\n",
      "Epoch: 9/20... Step: 1190... Loss: 1.4862... Val Loss: 1.4622\n",
      "Epoch: 9/20... Step: 1200... Loss: 1.4313... Val Loss: 1.4548\n",
      "Epoch: 9/20... Step: 1210... Loss: 1.4401... Val Loss: 1.4512\n",
      "Epoch: 9/20... Step: 1220... Loss: 1.4504... Val Loss: 1.4553\n",
      "Epoch: 9/20... Step: 1230... Loss: 1.4249... Val Loss: 1.4508\n",
      "Epoch: 9/20... Step: 1240... Loss: 1.4332... Val Loss: 1.4452\n",
      "Epoch: 9/20... Step: 1250... Loss: 1.4445... Val Loss: 1.4436\n",
      "Epoch: 10/20... Step: 1260... Loss: 1.4480... Val Loss: 1.4434\n",
      "Epoch: 10/20... Step: 1270... Loss: 1.4383... Val Loss: 1.4392\n",
      "Epoch: 10/20... Step: 1280... Loss: 1.4405... Val Loss: 1.4332\n",
      "Epoch: 10/20... Step: 1290... Loss: 1.4421... Val Loss: 1.4338\n",
      "Epoch: 10/20... Step: 1300... Loss: 1.4320... Val Loss: 1.4349\n",
      "Epoch: 10/20... Step: 1310... Loss: 1.4420... Val Loss: 1.4338\n",
      "Epoch: 10/20... Step: 1320... Loss: 1.4085... Val Loss: 1.4336\n",
      "Epoch: 10/20... Step: 1330... Loss: 1.4142... Val Loss: 1.4289\n",
      "Epoch: 10/20... Step: 1340... Loss: 1.3981... Val Loss: 1.4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Step: 1350... Loss: 1.3931... Val Loss: 1.4213\n",
      "Epoch: 10/20... Step: 1360... Loss: 1.3841... Val Loss: 1.4259\n",
      "Epoch: 10/20... Step: 1370... Loss: 1.3755... Val Loss: 1.4218\n",
      "Epoch: 10/20... Step: 1380... Loss: 1.4250... Val Loss: 1.4148\n",
      "Epoch: 10/20... Step: 1390... Loss: 1.4314... Val Loss: 1.4170\n",
      "Epoch: 11/20... Step: 1400... Loss: 1.4284... Val Loss: 1.4185\n",
      "Epoch: 11/20... Step: 1410... Loss: 1.4427... Val Loss: 1.4147\n",
      "Epoch: 11/20... Step: 1420... Loss: 1.4309... Val Loss: 1.4073\n",
      "Epoch: 11/20... Step: 1430... Loss: 1.3992... Val Loss: 1.4105\n",
      "Epoch: 11/20... Step: 1440... Loss: 1.4362... Val Loss: 1.4060\n",
      "Epoch: 11/20... Step: 1450... Loss: 1.3561... Val Loss: 1.4054\n",
      "Epoch: 11/20... Step: 1460... Loss: 1.3756... Val Loss: 1.4073\n",
      "Epoch: 11/20... Step: 1470... Loss: 1.3766... Val Loss: 1.4047\n",
      "Epoch: 11/20... Step: 1480... Loss: 1.3972... Val Loss: 1.3992\n",
      "Epoch: 11/20... Step: 1490... Loss: 1.3747... Val Loss: 1.3967\n",
      "Epoch: 11/20... Step: 1500... Loss: 1.3645... Val Loss: 1.3986\n",
      "Epoch: 11/20... Step: 1510... Loss: 1.3538... Val Loss: 1.3992\n",
      "Epoch: 11/20... Step: 1520... Loss: 1.3887... Val Loss: 1.3923\n",
      "Epoch: 12/20... Step: 1530... Loss: 1.4452... Val Loss: 1.3915\n",
      "Epoch: 12/20... Step: 1540... Loss: 1.3953... Val Loss: 1.3887\n",
      "Epoch: 12/20... Step: 1550... Loss: 1.3962... Val Loss: 1.3859\n",
      "Epoch: 12/20... Step: 1560... Loss: 1.4023... Val Loss: 1.3845\n",
      "Epoch: 12/20... Step: 1570... Loss: 1.3618... Val Loss: 1.3864\n",
      "Epoch: 12/20... Step: 1580... Loss: 1.3288... Val Loss: 1.3844\n",
      "Epoch: 12/20... Step: 1590... Loss: 1.3300... Val Loss: 1.3844\n",
      "Epoch: 12/20... Step: 1600... Loss: 1.3490... Val Loss: 1.3835\n",
      "Epoch: 12/20... Step: 1610... Loss: 1.3478... Val Loss: 1.3864\n",
      "Epoch: 12/20... Step: 1620... Loss: 1.3535... Val Loss: 1.3791\n",
      "Epoch: 12/20... Step: 1630... Loss: 1.3670... Val Loss: 1.3753\n",
      "Epoch: 12/20... Step: 1640... Loss: 1.3440... Val Loss: 1.3791\n",
      "Epoch: 12/20... Step: 1650... Loss: 1.3304... Val Loss: 1.3763\n",
      "Epoch: 12/20... Step: 1660... Loss: 1.3709... Val Loss: 1.3695\n",
      "Epoch: 13/20... Step: 1670... Loss: 1.3404... Val Loss: 1.3753\n",
      "Epoch: 13/20... Step: 1680... Loss: 1.3551... Val Loss: 1.3698\n",
      "Epoch: 13/20... Step: 1690... Loss: 1.3301... Val Loss: 1.3665\n",
      "Epoch: 13/20... Step: 1700... Loss: 1.3306... Val Loss: 1.3616\n",
      "Epoch: 13/20... Step: 1710... Loss: 1.3086... Val Loss: 1.3666\n",
      "Epoch: 13/20... Step: 1720... Loss: 1.3270... Val Loss: 1.3703\n",
      "Epoch: 13/20... Step: 1730... Loss: 1.3601... Val Loss: 1.3625\n",
      "Epoch: 13/20... Step: 1740... Loss: 1.3294... Val Loss: 1.3621\n",
      "Epoch: 13/20... Step: 1750... Loss: 1.2962... Val Loss: 1.3605\n",
      "Epoch: 13/20... Step: 1760... Loss: 1.3291... Val Loss: 1.3585\n",
      "Epoch: 13/20... Step: 1770... Loss: 1.3347... Val Loss: 1.3585\n",
      "Epoch: 13/20... Step: 1780... Loss: 1.3094... Val Loss: 1.3519\n",
      "Epoch: 13/20... Step: 1790... Loss: 1.3037... Val Loss: 1.3556\n",
      "Epoch: 13/20... Step: 1800... Loss: 1.3259... Val Loss: 1.3502\n",
      "Epoch: 14/20... Step: 1810... Loss: 1.3300... Val Loss: 1.3498\n",
      "Epoch: 14/20... Step: 1820... Loss: 1.3115... Val Loss: 1.3474\n",
      "Epoch: 14/20... Step: 1830... Loss: 1.3319... Val Loss: 1.3431\n",
      "Epoch: 14/20... Step: 1840... Loss: 1.2688... Val Loss: 1.3421\n",
      "Epoch: 14/20... Step: 1850... Loss: 1.2637... Val Loss: 1.3406\n",
      "Epoch: 14/20... Step: 1860... Loss: 1.3170... Val Loss: 1.3437\n",
      "Epoch: 14/20... Step: 1870... Loss: 1.3217... Val Loss: 1.3407\n",
      "Epoch: 14/20... Step: 1880... Loss: 1.3195... Val Loss: 1.3401\n",
      "Epoch: 14/20... Step: 1890... Loss: 1.3369... Val Loss: 1.3401\n",
      "Epoch: 14/20... Step: 1900... Loss: 1.2999... Val Loss: 1.3382\n",
      "Epoch: 14/20... Step: 1910... Loss: 1.3153... Val Loss: 1.3349\n",
      "Epoch: 14/20... Step: 1920... Loss: 1.3041... Val Loss: 1.3391\n",
      "Epoch: 14/20... Step: 1930... Loss: 1.2676... Val Loss: 1.3367\n",
      "Epoch: 14/20... Step: 1940... Loss: 1.3331... Val Loss: 1.3396\n",
      "Epoch: 15/20... Step: 1950... Loss: 1.3017... Val Loss: 1.3355\n",
      "Epoch: 15/20... Step: 1960... Loss: 1.3021... Val Loss: 1.3367\n",
      "Epoch: 15/20... Step: 1970... Loss: 1.2851... Val Loss: 1.3269\n",
      "Epoch: 15/20... Step: 1980... Loss: 1.2824... Val Loss: 1.3319\n",
      "Epoch: 15/20... Step: 1990... Loss: 1.2737... Val Loss: 1.3260\n",
      "Epoch: 15/20... Step: 2000... Loss: 1.2606... Val Loss: 1.3242\n",
      "Epoch: 15/20... Step: 2010... Loss: 1.2767... Val Loss: 1.3311\n",
      "Epoch: 15/20... Step: 2020... Loss: 1.3080... Val Loss: 1.3249\n",
      "Epoch: 15/20... Step: 2030... Loss: 1.2721... Val Loss: 1.3248\n",
      "Epoch: 15/20... Step: 2040... Loss: 1.2891... Val Loss: 1.3206\n",
      "Epoch: 15/20... Step: 2050... Loss: 1.2806... Val Loss: 1.3202\n",
      "Epoch: 15/20... Step: 2060... Loss: 1.2827... Val Loss: 1.3219\n",
      "Epoch: 15/20... Step: 2070... Loss: 1.2918... Val Loss: 1.3219\n",
      "Epoch: 15/20... Step: 2080... Loss: 1.2858... Val Loss: 1.3213\n",
      "Epoch: 16/20... Step: 2090... Loss: 1.2936... Val Loss: 1.3203\n",
      "Epoch: 16/20... Step: 2100... Loss: 1.2737... Val Loss: 1.3163\n",
      "Epoch: 16/20... Step: 2110... Loss: 1.2669... Val Loss: 1.3130\n",
      "Epoch: 16/20... Step: 2120... Loss: 1.2843... Val Loss: 1.3172\n",
      "Epoch: 16/20... Step: 2130... Loss: 1.2545... Val Loss: 1.3134\n",
      "Epoch: 16/20... Step: 2140... Loss: 1.2673... Val Loss: 1.3119\n",
      "Epoch: 16/20... Step: 2150... Loss: 1.2944... Val Loss: 1.3089\n",
      "Epoch: 16/20... Step: 2160... Loss: 1.2658... Val Loss: 1.3128\n",
      "Epoch: 16/20... Step: 2170... Loss: 1.2693... Val Loss: 1.3130\n",
      "Epoch: 16/20... Step: 2180... Loss: 1.2581... Val Loss: 1.3123\n",
      "Epoch: 16/20... Step: 2190... Loss: 1.2856... Val Loss: 1.3108\n",
      "Epoch: 16/20... Step: 2200... Loss: 1.2443... Val Loss: 1.3063\n",
      "Epoch: 16/20... Step: 2210... Loss: 1.2143... Val Loss: 1.3135\n",
      "Epoch: 16/20... Step: 2220... Loss: 1.2763... Val Loss: 1.3081\n",
      "Epoch: 17/20... Step: 2230... Loss: 1.2509... Val Loss: 1.3117\n",
      "Epoch: 17/20... Step: 2240... Loss: 1.2526... Val Loss: 1.3090\n",
      "Epoch: 17/20... Step: 2250... Loss: 1.2455... Val Loss: 1.3028\n",
      "Epoch: 17/20... Step: 2260... Loss: 1.2519... Val Loss: 1.3079\n",
      "Epoch: 17/20... Step: 2270... Loss: 1.2622... Val Loss: 1.3007\n",
      "Epoch: 17/20... Step: 2280... Loss: 1.2646... Val Loss: 1.2985\n",
      "Epoch: 17/20... Step: 2290... Loss: 1.2591... Val Loss: 1.3006\n",
      "Epoch: 17/20... Step: 2300... Loss: 1.2187... Val Loss: 1.3061\n",
      "Epoch: 17/20... Step: 2310... Loss: 1.2488... Val Loss: 1.3003\n",
      "Epoch: 17/20... Step: 2320... Loss: 1.2377... Val Loss: 1.3023\n",
      "Epoch: 17/20... Step: 2330... Loss: 1.2464... Val Loss: 1.3072\n",
      "Epoch: 17/20... Step: 2340... Loss: 1.2496... Val Loss: 1.2971\n",
      "Epoch: 17/20... Step: 2350... Loss: 1.2634... Val Loss: 1.2999\n",
      "Epoch: 17/20... Step: 2360... Loss: 1.2586... Val Loss: 1.2965\n",
      "Epoch: 18/20... Step: 2370... Loss: 1.2422... Val Loss: 1.2945\n",
      "Epoch: 18/20... Step: 2380... Loss: 1.2481... Val Loss: 1.2942\n",
      "Epoch: 18/20... Step: 2390... Loss: 1.2385... Val Loss: 1.3051\n",
      "Epoch: 18/20... Step: 2400... Loss: 1.2693... Val Loss: 1.2974\n",
      "Epoch: 18/20... Step: 2410... Loss: 1.2627... Val Loss: 1.2962\n",
      "Epoch: 18/20... Step: 2420... Loss: 1.2337... Val Loss: 1.2883\n",
      "Epoch: 18/20... Step: 2430... Loss: 1.2447... Val Loss: 1.2922\n",
      "Epoch: 18/20... Step: 2440... Loss: 1.2341... Val Loss: 1.2936\n",
      "Epoch: 18/20... Step: 2450... Loss: 1.2323... Val Loss: 1.2899\n",
      "Epoch: 18/20... Step: 2460... Loss: 1.2457... Val Loss: 1.2914\n",
      "Epoch: 18/20... Step: 2470... Loss: 1.2332... Val Loss: 1.2993\n",
      "Epoch: 18/20... Step: 2480... Loss: 1.2231... Val Loss: 1.2909\n",
      "Epoch: 18/20... Step: 2490... Loss: 1.2181... Val Loss: 1.2913\n",
      "Epoch: 18/20... Step: 2500... Loss: 1.2346... Val Loss: 1.2918\n",
      "Epoch: 19/20... Step: 2510... Loss: 1.2335... Val Loss: 1.2922\n",
      "Epoch: 19/20... Step: 2520... Loss: 1.2471... Val Loss: 1.2908\n",
      "Epoch: 19/20... Step: 2530... Loss: 1.2490... Val Loss: 1.2854\n",
      "Epoch: 19/20... Step: 2540... Loss: 1.2635... Val Loss: 1.2854\n",
      "Epoch: 19/20... Step: 2550... Loss: 1.2124... Val Loss: 1.2876\n",
      "Epoch: 19/20... Step: 2560... Loss: 1.2234... Val Loss: 1.2851\n",
      "Epoch: 19/20... Step: 2570... Loss: 1.2193... Val Loss: 1.2875\n",
      "Epoch: 19/20... Step: 2580... Loss: 1.2569... Val Loss: 1.2992\n",
      "Epoch: 19/20... Step: 2590... Loss: 1.2133... Val Loss: 1.2876\n",
      "Epoch: 19/20... Step: 2600... Loss: 1.2198... Val Loss: 1.2921\n",
      "Epoch: 19/20... Step: 2610... Loss: 1.2273... Val Loss: 1.2813\n",
      "Epoch: 19/20... Step: 2620... Loss: 1.2029... Val Loss: 1.2822\n",
      "Epoch: 19/20... Step: 2630... Loss: 1.2044... Val Loss: 1.2786\n",
      "Epoch: 19/20... Step: 2640... Loss: 1.2234... Val Loss: 1.2819\n",
      "Epoch: 20/20... Step: 2650... Loss: 1.2344... Val Loss: 1.2802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Step: 2660... Loss: 1.2336... Val Loss: 1.2819\n",
      "Epoch: 20/20... Step: 2670... Loss: 1.2329... Val Loss: 1.2765\n",
      "Epoch: 20/20... Step: 2680... Loss: 1.2183... Val Loss: 1.2775\n",
      "Epoch: 20/20... Step: 2690... Loss: 1.2269... Val Loss: 1.2758\n",
      "Epoch: 20/20... Step: 2700... Loss: 1.2301... Val Loss: 1.2785\n",
      "Epoch: 20/20... Step: 2710... Loss: 1.1988... Val Loss: 1.2817\n",
      "Epoch: 20/20... Step: 2720... Loss: 1.2052... Val Loss: 1.2792\n",
      "Epoch: 20/20... Step: 2730... Loss: 1.1917... Val Loss: 1.2770\n",
      "Epoch: 20/20... Step: 2740... Loss: 1.1990... Val Loss: 1.2773\n",
      "Epoch: 20/20... Step: 2750... Loss: 1.1967... Val Loss: 1.2780\n",
      "Epoch: 20/20... Step: 2760... Loss: 1.1961... Val Loss: 1.2748\n",
      "Epoch: 20/20... Step: 2770... Loss: 1.2353... Val Loss: 1.2739\n",
      "Epoch: 20/20... Step: 2780... Loss: 1.2497... Val Loss: 1.2741\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 20\n",
    "\n",
    "train(net,\n",
    "      encoded,\n",
    "      epochs=n_epochs,\n",
    "      batch_size=batch_size,\n",
    "      seq_length=seq_length,\n",
    "      lr=0.001,\n",
    "      print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取最优模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 过拟合与欠拟合\n",
    "    - 实时监控训练和验证损失，如果训练损失远远低于验证损失，则模型过拟合；添加正则化、`dropout`，或使用更小的模型；\n",
    "    - 如果训练和验证损失相近，则过拟合，可以增加模型的尺寸\n",
    "       \n",
    "    \n",
    "- 超参数    \n",
    "    - 模型定义时：隐藏层神经元数量`n_hidden`，`LSTM`的层数`n_layers`\n",
    "        - `n_layers`建议设置值2或3，模型的总参数量与训练数据量处于同样的量级；如100MB的数据，当模型150K参数，模型会严重欠拟合，而10MB数量模型10M参数，模型会欠拟合，增大`dropout`参数\n",
    "        - **总是训练较大的模型，然后尝试不同的`dropout`**\n",
    "    - 模型训练时：`batch_size`,`seq_length`,`lr`,及数据拆分为训练集及验证集的拆分比列\n",
    "        - 尝试不同的超参数组合，选择性能最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn_20_epoch.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:16:45.296088Z",
     "start_time": "2020-04-17T14:16:45.288854Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # topK采样\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:17:53.211901Z",
     "start_time": "2020-04-17T14:17:52.876013Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "with a smile to holding a person was, and a line white sheel, who\n",
      "did not know. His father was a long while, and her friend, and the\n",
      "secundes, time and some of or that some made a dress so as happy, and\n",
      "to see it. To her that he was not finished, he went into the same\n",
      "time, the princess had always taken up to the corridor, was in which\n",
      "the prevent position he was an expression to the table, and she could\n",
      "do to triem to herself what they seemed to the cletched of the\n",
      "coup of the sick man are a sinting state of charming head, was not to\n",
      "such her for his brother's woman that when they were since he was sitting to\n",
      "the soft might have been seening that her family and with the proviss,\n",
      "which she had been set off the same thing, who had been disagreeable\n",
      "and had sore of the propersy of always. And he set her. He spoke tran\n",
      "out of the stranger and her husband who had no supported\n",
      "that he had not heard the face of her starts, began to say, the pissons were\n",
      "far in shame, and her heart, their sho\n"
     ]
    }
   ],
   "source": [
    "# 文本生成\n",
    "def sample(net, size, prime='The', top_k=None):\n",
    "\n",
    "    if (train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "\n",
    "    net.eval()  # eval mode\n",
    "\n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "print(sample(net, 1000, prime='Anna', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
